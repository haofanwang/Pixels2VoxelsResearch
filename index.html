<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pixels2Voxels Research (P2VR)</title>

    <style>
        .box {
            border-radius: 10px;
            margin: 0 auto;
            padding-left: 60px;
            padding-right: 60px;
            width: 760px;
            background-color: white;
            box-shadow: black 0px 0px 32px;
        }

        .bgb {
            background-color: rgb(240, 240, 240);
            padding-left: 60px;
            padding-right: 10px;
            padding-top: 5px;
            padding-bottom: 5px;
            margin-top: 40px;
            margin-left: -45pt;
            margin-right: -45pt;
            font-weight: bold;
        }

        .item {
            margin-top: 20px;
        }

        .left-img {
            border-radius: 10px;
            display: inline-block;
            vertical-align: top;
            width: 35%;
            margin-right: 4%;
        }

        .right-text {
            display: inline-block;
            width: 60%;
        }

        .dot {
            height: 14px;
            width: 14px;
            background-color: #bbb;
            border-radius: 50%;
            display: inline-block;
            margin-right: 8px;
        }
    </style>

</head>

<body style="background-color:rgb(48, 48, 48);">
    </br></br></br>
    <div class="box">
        <div class="block">
            <img src="imgs/logo.png"
                style="width: 1024px; margin-left: -60px; border-top-right-radius: 10px;border-top-left-radius: 10px;"  /></br>
                Pixels2Voxels Research (P2VR) is a non-commercial and voluntary research group, established in February 2023, not affiliated with any official institution, dedicated to promoting extensive academic research cooperation.
                The team currently has 7 senior researchers and 10 researchers. Our research mainly includes multimodal and 3D virtual digital human. More specifically, the multimodal direction includes multimodal representation learning, audio-visual localization, commonsense reasoning, and the digital human direction includes controllable image/video generation, 3D avatar reconstruction and generation, conditional human motion generation, human-aware 3D scene generation.
                Our main target is to publish influential academic papers in the top conferences such as CVPR/ICCV/ECCV/SIGGRAPH. To join us, you have to be self-motivated and have published at least one related paper on the top tier conferences.
        </div>

        <div class="tex">
            <div class="bgb">News</div>
            <p>
                2023.02 - We teammates got 5 papers accepted to CVPR 2023.</br>
                2023.02 - Pixels2Voxels Research is founded for spontaneous research cooperation.</br>
            </p>
        </div>

        <div class="tex">
            <a name="research">
                <div class="bgb">Member</div>
            </a>
            <p>
                <span class="dot" style="background-color:navy"></span><a href="https://haofanwang.github.io/">Haofan Wang</a>
                <span class="dot" style="background-color:navy"></span><a href="https://xyyhw.top/">Hongwei Yi</a>
                <span class="dot" style="background-color:navy"></span><a href="https://keras.me/">Qiongjie Cui</a>
                <span class="dot" style="background-color:navy"></span><a href="http://wangjingbo.top/">Jingbo Wang</a>
                <span class="dot" style="background-color:navy"></span><a href="https://yzhq97.github.io/">Zhuoqian Yang</a>
                <span class="dot" style="background-color:navy"></span><a href="https://dingpx.github.io/">Pengxiang Ding</a>
                <span class="dot" style="background-color:navy"></span><a href="https://yzmblog.github.io/">Zhengming Yu</a>
                <span class="dot" style="background-color:navy"></span><a href="https://jinluzhang.site/">Jinlu Zhang</a>
                <span class="dot" style="background-color:navy"></span><a href="https://scholar.google.com/citations?user=SO-JS9EAAAAJ&hl=zh-CN">Jiale Xu</a>
                <span class="dot" style="background-color:navy"></span>Antong Chen
                <span class="dot" style="background-color:navy"></span>Yangyi Huang
                <span class="dot" style="background-color:navy"></span>Tingting Liao
                <span class="dot" style="background-color:navy"></span>Liang Pan
            </p>
            <p>
                <span class="dot" style="background-color:darkgreen"></span>Shentong Mo
                <span class="dot" style="background-color:darkgreen"></span>Rui Sun
                <span class="dot" style="background-color:darkgreen"></span><a href="https://yulu.net.cn/">Yu Lu</a>
                <span class="dot" style="background-color:darkgreen"></span><a href="https://github.com/PeterQiu0516">Changyuan Qiu</a>
            </p>
        </div>

        <!-- <div class="tex">
            <div class="bgb">Research</div>
            <div class="item">
                <img class="left-img" src="ins/sa22.png" />
                <div class="right-text">
                    <b>Sprite-from-Sprite: Cartoon Animation Decomposition with Self-supervised Sprite Estimation</b>,
                    </br>in ACM Transactions on Graphics (SIGGRAPH ASIA 2022, Journal Track).
                    </br>
                    <span class="dot" style="background-color:navy"></span><a href="https://github.com/lllyasviel">Lvmin
                        Zhang</a>, Tien-Tsin Wong, and
                    Yuxin Liu.
                    </br>
                    <small>The "sprites" in real-world cartoons are unique: artists may draw arbitrary sprite animations
                        for expressiveness, or alternatively, artists may also reduce their workload by tweening and
                        adjusting contents. Can we use these properties to do a "reverse engineering" to get the
                        original sprites in digital animation?
                        <a href="https://lllyasviel.github.io/GitPageToonDecompose/">Know more
                            ...</a></small>
                </div>
            </div>
        </div> -->

        <div class="tex">
            <div class="bgb">Contact Us</div>
            <ul style="padding-left: 24px;">
                <li style="padding-bottom: 10px;">To contact Pixels2Voxels Research for academic/commercial
                    collaboration, please send e-mail to haofanwang.ai@gmail.com with
                    "Interested in Pixels2Voxels Research" in your e-mail title, and breifly introduce your research background.</li>
            </ul>
        </div>

        <!-- </br></br>
        <p style="text-align:center;"><a href="https://www.easycounter.com/">
                <img src="https://www.easycounter.com/counter.php?lvmin" alt="Free Web Counter"></a>
        </p></br> -->

    </div>
    </br></br></br>
</body>
